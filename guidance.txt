# ğŸ¯ å°ç™½å®æ–½æŒ‡å—ï¼šå°†è¯­éŸ³åˆ†ææ¨¡å—é›†æˆåˆ°ä½ çš„é¡¹ç›®

## ğŸ“‹ ä½ çš„ç›®æ ‡

å®ç°ä¸€ä¸ª API æ¨¡å—ï¼ŒåŠŸèƒ½æ˜¯ï¼š

```
Bot å‘é€è¯­éŸ³ â†’ ä½ çš„ API æ¥æ”¶
    â†“
åˆ†å‘ç»™ 3 ä¸ª AI éªŒè¯èŠ‚ç‚¹
    â†“
æ¯ä¸ª AI åˆ†æ + BLS ç­¾å
    â†“
è¿”å›ï¼šå…¬é’¥ã€ç­¾åã€åˆ†æç»“æœ
```

---

## ğŸ“‚ ä½ çš„é¡¹ç›®ç»“æ„

æ ¹æ®ä½ çš„ GitHub é¡¹ç›®ï¼Œç›®å½•æ˜¯ï¼š

```
echorank/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/              # å‰ç«¯ï¼ˆä½ ä¸éœ€è¦æ”¹ï¼‰
â”‚   â””â”€â”€ server/           # â­ åç«¯ï¼ˆä½ è¦æ”¹è¿™é‡Œï¼‰
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ api/
â”‚               â”œâ”€â”€ activity.ts
â”‚               â”œâ”€â”€ analyze.ts     # â­ ä½ è¦åˆ›å»º/ä¿®æ”¹
â”‚               â””â”€â”€ register.ts
â”‚
â”œâ”€â”€ services/
â”‚   â””â”€â”€ ai/              # â­ Python AI æœåŠ¡ï¼ˆä½ è¦åˆ›å»ºï¼‰
â”‚       â”œâ”€â”€ validator.py         # ä¸»ç¨‹åº
â”‚       â”œâ”€â”€ analyzer.py          # SenseVoice
â”‚       â”œâ”€â”€ bls_signer.py        # BLS ç­¾å
â”‚       â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ contracts/           # æ™ºèƒ½åˆçº¦ï¼ˆæš‚æ—¶ä¸ç”¨ç®¡ï¼‰
```

---

## ğŸš€ ç¬¬ä¸€æ­¥ï¼šå®‰è£… Python AI æœåŠ¡

### 1.1 åˆ›å»º services/ai ç›®å½•

```bash
# è¿›å…¥ä½ çš„é¡¹ç›®æ ¹ç›®å½•
cd echorank

# åˆ›å»º AI æœåŠ¡ç›®å½•
mkdir -p services/ai
cd services/ai
```

### 1.2 åˆ›å»ºæ–‡ä»¶

ä½ éœ€è¦åˆ›å»º 4 ä¸ªæ–‡ä»¶ï¼š

1. **validator.py** - ä¸»ç¨‹åºï¼ˆæˆ‘å·²ç»å†™å¥½äº†ï¼‰
2. **analyzer.py** - SenseVoice åˆ†æå™¨
3. **bls_signer.py** - BLS ç­¾å
4. **requirements.txt** - Python ä¾èµ–

---

## ğŸ“ ç¬¬äºŒæ­¥ï¼šå¤åˆ¶ä»£ç æ–‡ä»¶

### 2.1 åˆ›å»º `requirements.txt`

```bash
# åœ¨ services/ai/ ç›®å½•ä¸‹åˆ›å»ºæ–‡ä»¶
nano requirements.txt
```

**å¤åˆ¶ä»¥ä¸‹å†…å®¹ï¼š**

```txt
# Web æ¡†æ¶
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
python-multipart==0.0.6

# AI æ¨¡å‹
funasr>=1.0.0
torch>=2.0.0
torchaudio>=2.0.0
numpy>=1.24.0
modelscope>=1.9.0

# BLS ç­¾å
py-ecc==6.0.0

# å·¥å…·
python-dotenv==1.0.0
```

**ä¿å­˜å¹¶é€€å‡º**ï¼ˆCtrl+O, Enter, Ctrl+Xï¼‰

### 2.2 åˆ›å»º `analyzer.py`

```bash
nano analyzer.py
```

**å¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š**

```python
# analyzer.py - SenseVoice æƒ…æ„Ÿåˆ†æå™¨
"""
ä½¿ç”¨ SenseVoice-Small æ¨¡å‹åˆ†æè¯­éŸ³æƒ…æ„Ÿ
"""

import io
import re
import numpy as np
import torch
import torchaudio
from funasr import AutoModel
from typing import Dict, Tuple, List
import logging

logger = logging.getLogger(__name__)


class EmotionAnalyzer:
    """è¯­éŸ³æƒ…æ„Ÿåˆ†æå™¨"""
    
    # æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„
    EMO_DICT = {
        "<|HAPPY|>": "HAPPY",
        "<|SAD|>": "SAD",
        "<|ANGRY|>": "ANGRY",
        "<|NEUTRAL|>": "NEUTRAL",
        "<|FEARFUL|>": "FEARFUL",
        "<|DISGUSTED|>": "DISGUSTED",
        "<|SURPRISED|>": "SURPRISED",
    }
    
    # éŸ³é¢‘äº‹ä»¶æ˜ å°„
    EVENT_DICT = {
        "<|BGM|>": "music",
        "<|Speech|>": "speech",
        "<|Applause|>": "applause",
        "<|Laughter|>": "laughter",
        "<|Cry|>": "cry",
        "<|Sneeze|>": "sneeze",
        "<|Cough|>": "cough",
    }
    
    def __init__(self, model_path="iic/SenseVoiceSmall"):
        """åˆå§‹åŒ– SenseVoice æ¨¡å‹"""
        logger.info("Loading SenseVoice model...")
        
        self.model = AutoModel(
            model=model_path,
            vad_model="iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            vad_kwargs={"max_single_segment_time": 30000},
            trust_remote_code=True,
        )
        
        logger.info("SenseVoice model loaded successfully")
    
    def analyze(self, audio_bytes: bytes) -> Dict:
        """
        åˆ†æéŸ³é¢‘æƒ…æ„Ÿ
        
        å‚æ•°:
            audio_bytes: éŸ³é¢‘å­—èŠ‚æ•°æ®
        
        è¿”å›:
            {
                "emotion": "HAPPY",
                "intensity": 0.85,
                "confidence": 0.92,
                "keywords": ["æ´»åŠ¨", "å¾ˆæ£’"],
                "events": ["applause"],
                "raw_text": "è¿™æ¬¡æ´»åŠ¨å¾ˆæ£’ï¼",
                "language": "zh"
            }
        """
        # é¢„å¤„ç†éŸ³é¢‘
        audio_array, sample_rate = self._preprocess_audio(audio_bytes)
        
        # è¿è¡Œ SenseVoice æ¨ç†
        result = self.model.generate(
            input=audio_array,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=60,
            merge_vad=True
        )
        
        # è§£æç»“æœ
        raw_text = result[0]["text"]
        
        emotion, intensity = self._extract_emotion(raw_text)
        events = self._extract_events(raw_text)
        language = self._extract_language(raw_text)
        clean_text = self._clean_text(raw_text)
        keywords = self._extract_keywords(clean_text)
        
        return {
            "emotion": emotion,
            "intensity": intensity,
            "confidence": intensity,  # SenseVoice çš„å¼ºåº¦å¯ä½œä¸ºç½®ä¿¡åº¦
            "keywords": keywords,
            "events": events,
            "raw_text": clean_text,
            "language": language,
            "full_result": raw_text  # ä¿ç•™åŸå§‹ç»“æœç”¨äºè°ƒè¯•
        }
    
    def _preprocess_audio(self, audio_bytes: bytes) -> Tuple[np.ndarray, int]:
        """é¢„å¤„ç†éŸ³é¢‘æ•°æ®"""
        # ä»å­—èŠ‚åŠ è½½éŸ³é¢‘
        audio_buffer = io.BytesIO(audio_bytes)
        
        try:
            # å°è¯•åŠ è½½éŸ³é¢‘
            waveform, sample_rate = torchaudio.load(audio_buffer)
        except Exception as e:
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½œä¸ºåŸå§‹ PCM æ•°æ®
            audio_array = np.frombuffer(audio_bytes, dtype=np.int16)
            audio_array = audio_array.astype(np.float32) / 32768.0
            sample_rate = 16000
            
            return audio_array, sample_rate
        
        # è½¬æ¢ä¸º numpy
        audio_array = waveform.numpy()
        
        # è½¬ä¸ºå•å£°é“
        if len(audio_array.shape) > 1 and audio_array.shape[0] > 1:
            audio_array = audio_array.mean(axis=0)
        else:
            audio_array = audio_array.squeeze()
        
        # é‡é‡‡æ ·åˆ° 16kHz
        if sample_rate != 16000:
            resampler = torchaudio.transforms.Resample(sample_rate, 16000)
            audio_tensor = torch.from_numpy(audio_array).float()
            if len(audio_tensor.shape) == 1:
                audio_tensor = audio_tensor.unsqueeze(0)
            audio_array = resampler(audio_tensor).squeeze().numpy()
            sample_rate = 16000
        
        return audio_array, sample_rate
    
    def _extract_emotion(self, text: str) -> Tuple[str, float]:
        """æå–æƒ…æ„Ÿæ ‡ç­¾å’Œå¼ºåº¦"""
        emotion_counts = {}
        
        for tag, emotion in self.EMO_DICT.items():
            count = text.count(tag)
            if count > 0:
                emotion_counts[emotion] = count
        
        if not emotion_counts:
            return "NEUTRAL", 0.5
        
        # æ‰¾å‡ºå‡ºç°æœ€å¤šçš„æƒ…æ„Ÿ
        dominant_emotion = max(emotion_counts, key=emotion_counts.get)
        count = emotion_counts[dominant_emotion]
        
        # è®¡ç®—å¼ºåº¦ï¼ˆå‡ºç°æ¬¡æ•°è¶Šå¤šï¼Œå¼ºåº¦è¶Šé«˜ï¼‰
        intensity = min(0.7 + (count - 1) * 0.1, 0.99)
        
        return dominant_emotion, intensity
    
    def _extract_events(self, text: str) -> List[str]:
        """æå–éŸ³é¢‘äº‹ä»¶"""
        events = []
        
        for tag, event in self.EVENT_DICT.items():
            if tag in text and event not in ['speech', 'breath']:
                events.append(event)
        
        return events
    
    def _extract_language(self, text: str) -> str:
        """æå–æ£€æµ‹åˆ°çš„è¯­è¨€"""
        lang_tags = {
            "<|zh|>": "zh",
            "<|en|>": "en",
            "<|yue|>": "yue",
            "<|ja|>": "ja",
            "<|ko|>": "ko",
        }
        
        for tag, lang in lang_tags.items():
            if tag in text:
                return lang
        
        return "unknown"
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æ‰€æœ‰æ ‡ç­¾"""
        # ç§»é™¤æ‰€æœ‰ <|xxx|> æ ¼å¼çš„æ ‡ç­¾
        cleaned = re.sub(r'<\|[^>]+\|>', '', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cleaned = ' '.join(cleaned.split())
        
        return cleaned.strip()
    
    def _extract_keywords(self, text: str, max_keywords: int = 5) -> List[str]:
        """ç®€å•çš„å…³é”®è¯æå–ï¼ˆæŒ‰è¯é¢‘ï¼‰"""
        if not text:
            return []
        
        # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼‰
        words = re.findall(r'\w+', text)
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {'çš„', 'äº†', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬'}
        words = [w for w in words if len(w) > 1 and w not in stop_words]
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # æŒ‰é¢‘ç‡æ’åºï¼Œå–å‰ N ä¸ª
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        keywords = [word for word, freq in sorted_words[:max_keywords]]
        
        return keywords


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import sys
    
    logging.basicConfig(level=logging.INFO)
    
    analyzer = EmotionAnalyzer()
    print("âœ… Analyzer initialized successfully")
    
    if len(sys.argv) > 1:
        # æµ‹è¯•æ–‡ä»¶
        audio_file = sys.argv[1]
        with open(audio_file, 'rb') as f:
            audio_bytes = f.read()
        
        result = analyzer.analyze(audio_bytes)
        print("\nåˆ†æç»“æœ:")
        print(f"  æƒ…æ„Ÿ: {result['emotion']}")
        print(f"  å¼ºåº¦: {result['intensity']:.2f}")
        print(f"  è½¬å½•: {result['raw_text']}")
        print(f"  å…³é”®è¯: {result['keywords']}")
```

**ä¿å­˜å¹¶é€€å‡º**

### 2.3 åˆ›å»º `bls_signer.py`

```bash
nano bls_signer.py
```

**å¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š**

```python
# bls_signer.py - BLS ç­¾åå®ç°
"""
ä½¿ç”¨ BLS12-381 æ›²çº¿å®ç°é˜ˆå€¼ç­¾å
"""

from py_ecc.bls import G2ProofOfPossession as bls
import hashlib
import logging

logger = logging.getLogger(__name__)


class BLSSigner:
    """BLS ç­¾åå™¨"""
    
    def __init__(self, private_key_hex: str):
        """
        åˆå§‹åŒ–ç­¾åå™¨
        
        å‚æ•°:
            private_key_hex: ç§é’¥çš„åå…­è¿›åˆ¶å­—ç¬¦ä¸²
        """
        self.sk = int(private_key_hex, 16)
        self.pk = bls.SkToPk(self.sk)
        
        logger.info(f"BLS Signer initialized with public key: {self.pk.hex()[:16]}...")
    
    def sign_message(self, message: bytes) -> bytes:
        """
        å¯¹æ¶ˆæ¯è¿›è¡Œ BLS ç­¾å
        
        å‚æ•°:
            message: å¾…ç­¾åçš„æ¶ˆæ¯ï¼ˆå­—èŠ‚ï¼‰
        
        è¿”å›:
            ç­¾åï¼ˆå­—èŠ‚ï¼‰
        """
        signature = bls.Sign(self.sk, message)
        return signature
    
    @staticmethod
    def verify_signature(public_key: bytes, message: bytes, signature: bytes) -> bool:
        """
        éªŒè¯ BLS ç­¾å
        
        å‚æ•°:
            public_key: å…¬é’¥
            message: åŸå§‹æ¶ˆæ¯
            signature: ç­¾å
        
        è¿”å›:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            return bls.Verify(public_key, message, signature)
        except Exception as e:
            logger.error(f"Signature verification failed: {e}")
            return False
    
    @staticmethod
    def aggregate_signatures(signatures: list) -> bytes:
        """
        èšåˆå¤šä¸ªç­¾å
        
        å‚æ•°:
            signatures: ç­¾ååˆ—è¡¨
        
        è¿”å›:
            èšåˆç­¾å
        """
        return bls.Aggregate(signatures)
    
    @staticmethod
    def aggregate_verify(
        public_keys: list,
        message: bytes,
        aggregated_sig: bytes
    ) -> bool:
        """
        éªŒè¯èšåˆç­¾åï¼ˆæ‰€æœ‰èŠ‚ç‚¹ç­¾ç½²åŒä¸€æ¶ˆæ¯ï¼‰
        
        å‚æ•°:
            public_keys: å…¬é’¥åˆ—è¡¨
            message: åŸå§‹æ¶ˆæ¯
            aggregated_sig: èšåˆç­¾å
        
        è¿”å›:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # èšåˆå…¬é’¥
            agg_pk = public_keys[0]
            for pk in public_keys[1:]:
                agg_pk = bls.aggregate_pubkeys([agg_pk, pk])
            
            # éªŒè¯èšåˆç­¾å
            return bls.Verify(agg_pk, message, aggregated_sig)
        except Exception as e:
            logger.error(f"Aggregated signature verification failed: {e}")
            return False


def construct_message(
    audio_hash: str,
    result_hash: str,
    algo_version: str,
    timestamp: int,
    nonce: str
) -> bytes:
    """
    æ„é€ å¾…ç­¾åæ¶ˆæ¯
    
    æ¶ˆæ¯æ ¼å¼:
    m = domain_sep || audio_hash || result_hash || algo_version || timestamp || nonce
    
    å‚æ•°:
        audio_hash: éŸ³é¢‘å“ˆå¸Œ
        result_hash: ç»“æœå“ˆå¸Œ
        algo_version: ç®—æ³•ç‰ˆæœ¬
        timestamp: æ—¶é—´æˆ³
        nonce: éšæœºæ•°
    
    è¿”å›:
        æ¶ˆæ¯çš„ SHA256 å“ˆå¸Œ
    """
    domain_sep = "ECHORANK_V1"
    
    message_parts = [
        domain_sep,
        audio_hash,
        result_hash,
        algo_version,
        str(timestamp),
        nonce
    ]
    
    message_str = "||".join(message_parts)
    message_bytes = message_str.encode('utf-8')
    
    # è¿”å›æ¶ˆæ¯çš„å“ˆå¸Œï¼ˆæ ‡å‡†åšæ³•ï¼‰
    return hashlib.sha256(message_bytes).digest()


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import secrets
    import time
    
    logging.basicConfig(level=logging.INFO)
    
    # ç”Ÿæˆæµ‹è¯•å¯†é’¥
    sk_hex = hex(secrets.randbelow(bls.curve_order))
    print(f"Private Key: {sk_hex}")
    
    # åˆ›å»ºç­¾åå™¨
    signer = BLSSigner(sk_hex)
    print(f"Public Key: {signer.pk.hex()}")
    
    # æ„é€ æµ‹è¯•æ¶ˆæ¯
    message = construct_message(
        audio_hash="test_audio_hash",
        result_hash="test_result_hash",
        algo_version="v1.0.0",
        timestamp=int(time.time()),
        nonce=secrets.token_hex(16)
    )
    
    # ç­¾å
    signature = signer.sign_message(message)
    print(f"\nSignature: {signature.hex()[:32]}...")
    
    # éªŒè¯
    is_valid = BLSSigner.verify_signature(signer.pk, message, signature)
    print(f"Verification: {'âœ… Valid' if is_valid else 'âŒ Invalid'}")
```

**ä¿å­˜å¹¶é€€å‡º**

### 2.4 å¤åˆ¶ `validator.py`

æˆ‘ä¹‹å‰å·²ç»åˆ›å»ºå¥½äº†å®Œæ•´çš„ validator.pyï¼Œä½ éœ€è¦æŠŠå®ƒå¤åˆ¶åˆ° services/ai/ ç›®å½•ã€‚

ä»æˆ‘æä¾›çš„æ–‡ä»¶ä¸­å¤åˆ¶ï¼Œæˆ–è€…ç›´æ¥ä»è¾“å‡ºæ–‡ä»¶å¤¹ä¸­è·å–ã€‚

---

## ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šå®‰è£… Python ä¾èµ–

```bash
# ç¡®ä¿åœ¨ services/ai/ ç›®å½•
cd services/ai

# å®‰è£…ä¾èµ–
pip install -r requirements.txt --break-system-packages

# ä¸‹è½½ SenseVoice æ¨¡å‹
python -c "from modelscope import snapshot_download; snapshot_download('iic/SenseVoiceSmall'); snapshot_download('iic/speech_fsmn_vad_zh-cn-16k-common-pytorch')"
```

è¿™ä¸€æ­¥å¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿä¸‹è½½æ¨¡å‹ã€‚

---

## ğŸ”‘ ç¬¬å››æ­¥ï¼šç”Ÿæˆ BLS å¯†é’¥

### 4.1 åˆ›å»ºå¯†é’¥ç”Ÿæˆè„šæœ¬

```bash
# å›åˆ°é¡¹ç›®æ ¹ç›®å½•
cd ../..

# åˆ›å»º scripts ç›®å½•
mkdir -p scripts
cd scripts

# åˆ›å»ºå¯†é’¥ç”Ÿæˆè„šæœ¬
nano generate_keys.py
```

**å¤åˆ¶ä»¥ä¸‹ä»£ç ï¼š**

```python
#!/usr/bin/env python3
# generate_keys.py - ç”Ÿæˆ BLS å¯†é’¥å¯¹

import sys
sys.path.append('../services/ai')

from py_ecc.bls import G2ProofOfPossession as bls
import secrets

def generate_validator_keys(validator_id: int):
    """ä¸ºéªŒè¯èŠ‚ç‚¹ç”Ÿæˆ BLS å¯†é’¥å¯¹"""
    # ç”Ÿæˆç§é’¥ï¼ˆéšæœºæ•°ï¼‰
    sk = secrets.randbelow(bls.curve_order)
    
    # æ´¾ç”Ÿå…¬é’¥
    pk = bls.SkToPk(sk)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    sk_file = f'validator_{validator_id}_sk.key'
    pk_file = f'validator_{validator_id}_pk.key'
    
    with open(sk_file, 'w') as f:
        f.write(hex(sk))
    
    with open(pk_file, 'w') as f:
        f.write(pk.hex())
    
    print(f"âœ… Validator {validator_id} keys generated:")
    print(f"   Private Key: {hex(sk)}")
    print(f"   Public Key: {pk.hex()}")
    print(f"   Files: {sk_file}, {pk_file}\n")
    
    return hex(sk), pk.hex()


if __name__ == "__main__":
    print("="*60)
    print(" BLS Key Generation for EchoRank DVT Validators")
    print("="*60)
    print()
    
    # ä¸º 3 ä¸ªéªŒè¯èŠ‚ç‚¹ç”Ÿæˆå¯†é’¥
    keys = []
    for i in range(1, 4):
        sk, pk = generate_validator_keys(i)
        keys.append((sk, pk))
    
    print("="*60)
    print(" âš ï¸  IMPORTANT: Save these keys securely!")
    print("="*60)
    print()
    print("Add to your .env file:")
    print()
    for i, (sk, pk) in enumerate(keys, 1):
        print(f"VALIDATOR_{i}_SK={sk}")
    print()
```

**ä¿å­˜å¹¶é€€å‡º**

### 4.2 è¿è¡Œå¯†é’¥ç”Ÿæˆè„šæœ¬

```bash
# è¿è¡Œè„šæœ¬
python generate_keys.py
```

ä½ ä¼šçœ‹åˆ°è¾“å‡ºï¼š

```
============================================================
 BLS Key Generation for EchoRank DVT Validators
============================================================

âœ… Validator 1 keys generated:
   Private Key: 0x123abc...
   Public Key: 0xabc123...
   Files: validator_1_sk.key, validator_1_pk.key

...

Add to your .env file:

VALIDATOR_1_SK=0x123abc...
VALIDATOR_2_SK=0x456def...
VALIDATOR_3_SK=0x789ghi...
```

**âš ï¸ é‡è¦ï¼šä¿å­˜è¿™äº›ç§é’¥ï¼**

---

## ğŸŒ ç¬¬äº”æ­¥ï¼šä¿®æ”¹ Node.js åç«¯

ç°åœ¨ä¿®æ”¹ `apps/server/src/api/analyze.ts`

### 5.1 æŸ¥çœ‹ç°æœ‰çš„ analyze.ts

```bash
cd ../../apps/server/src/api
cat analyze.ts
```

### 5.2 ä¿®æ”¹ analyze.ts

```bash
nano analyze.ts
```

**ç”¨ä»¥ä¸‹ä»£ç æ›¿æ¢æˆ–æ·»åŠ ï¼š**

```typescript
// analyze.ts - è¯­éŸ³åˆ†æ API ç«¯ç‚¹
import { Router, Request, Response } from 'express';
import axios from 'axios';
import crypto from 'crypto';

const router = Router();

// ==================== é…ç½® ====================

const VALIDATOR_URLS = [
  process.env.VALIDATOR_1_URL || 'http://localhost:8001',
  process.env.VALIDATOR_2_URL || 'http://localhost:8002',
  process.env.VALIDATOR_3_URL || 'http://localhost:8003'
];

const THRESHOLD = 2; // 2-of-3

// ==================== ç±»å‹å®šä¹‰ ====================

interface AnalyzeRequest {
  audio: string;          // base64 ç¼–ç çš„éŸ³é¢‘
  audio_hash?: string;    // å¯é€‰ï¼šå®¢æˆ·ç«¯æä¾›çš„å“ˆå¸Œ
  user_id: string;
  activity_id?: string;
}

interface ValidatorResponse {
  task_id: string;
  validator_id: string;
  public_key: string;
  signature: string;
  result_json: {
    emotion: string;
    intensity: number;
    keywords: string[];
    events: string[];
    raw_text: string;
  };
  result_hash: string;
  algo_version: string;
  timestamp: number;
  nonce: string;
}

// ==================== å·¥å…·å‡½æ•° ====================

/**
 * è®¡ç®—éŸ³é¢‘çš„ SHA256 å“ˆå¸Œ
 */
function calculateAudioHash(audioBase64: string): string {
  const buffer = Buffer.from(audioBase64, 'base64');
  return crypto.createHash('sha256').update(buffer).digest('hex');
}

/**
 * å‘å•ä¸ªéªŒè¯èŠ‚ç‚¹å‘é€è¯·æ±‚
 */
async function requestValidator(
  validatorUrl: string,
  taskId: string,
  audioBase64: string,
  audioHash: string
): Promise<ValidatorResponse> {
  try {
    const response = await axios.post(
      `${validatorUrl}/analyze`,
      {
        task_id: taskId,
        audio_base64: audioBase64,
        audio_hash: audioHash
      },
      {
        timeout: 60000, // 60ç§’è¶…æ—¶
        headers: {
          'Content-Type': 'application/json'
        }
      }
    );
    
    return response.data;
  } catch (error: any) {
    console.error(`Validator ${validatorUrl} failed:`, error.message);
    throw error;
  }
}

/**
 * å¹¶è¡Œè¯·æ±‚æ‰€æœ‰éªŒè¯èŠ‚ç‚¹
 */
async function distributeToValidators(
  taskId: string,
  audioBase64: string,
  audioHash: string
): Promise<ValidatorResponse[]> {
  const promises = VALIDATOR_URLS.map(url =>
    requestValidator(url, taskId, audioBase64, audioHash)
  );
  
  // ä½¿ç”¨ Promise.allSettled ç¡®ä¿å³ä½¿éƒ¨åˆ†å¤±è´¥ä¹Ÿèƒ½ç»§ç»­
  const results = await Promise.allSettled(promises);
  
  // è¿‡æ»¤å‡ºæˆåŠŸçš„ç»“æœ
  const successful = results
    .filter((r): r is PromiseFulfilledResult<ValidatorResponse> => 
      r.status === 'fulfilled'
    )
    .map(r => r.value);
  
  if (successful.length < THRESHOLD) {
    throw new Error(
      `Insufficient validators responded (${successful.length}/${VALIDATOR_URLS.length})`
    );
  }
  
  return successful;
}

/**
 * éªŒè¯æ‰€æœ‰éªŒè¯èŠ‚ç‚¹çš„ç»“æœä¸€è‡´æ€§
 */
function verifyConsistency(validatorResults: ValidatorResponse[]): boolean {
  if (validatorResults.length < 2) return false;
  
  // æ£€æŸ¥ result_hash æ˜¯å¦ä¸€è‡´
  const resultHashes = validatorResults.map(v => v.result_hash);
  const uniqueHashes = new Set(resultHashes);
  
  if (uniqueHashes.size > 1) {
    console.error('Validators returned different result_hash:', resultHashes);
    return false;
  }
  
  return true;
}

// ==================== API ç«¯ç‚¹ ====================

/**
 * POST /api/analyze
 * 
 * æ¥æ”¶è¯­éŸ³ï¼Œåˆ†å‘åˆ°éªŒè¯èŠ‚ç‚¹ï¼Œè¿”å›ç­¾åç»“æœ
 */
router.post('/analyze', async (req: Request, res: Response) => {
  try {
    const { audio, audio_hash, user_id, activity_id }: AnalyzeRequest = req.body;
    
    // ========== 1. éªŒè¯è¾“å…¥ ==========
    if (!audio) {
      return res.status(400).json({ error: 'Missing audio data' });
    }
    
    if (!user_id) {
      return res.status(400).json({ error: 'Missing user_id' });
    }
    
    console.log(`[Analyze] Received request from user ${user_id}`);
    
    // ========== 2. éªŒè¯éŸ³é¢‘å“ˆå¸Œ ==========
    const calculatedHash = calculateAudioHash(audio);
    
    if (audio_hash && audio_hash !== calculatedHash) {
      console.error(
        `Audio hash mismatch: expected=${audio_hash}, actual=${calculatedHash}`
      );
      return res.status(400).json({
        error: 'Audio hash mismatch',
        expected: audio_hash,
        actual: calculatedHash
      });
    }
    
    const finalAudioHash = audio_hash || calculatedHash;
    console.log(`[Analyze] Audio hash verified: ${finalAudioHash.substring(0, 16)}...`);
    
    // ========== 3. ç”Ÿæˆä»»åŠ¡ ID ==========
    const taskId = crypto.randomUUID();
    console.log(`[Analyze] Task ID: ${taskId}`);
    
    // ========== 4. åˆ†å‘åˆ°éªŒè¯èŠ‚ç‚¹ ==========
    console.log(`[Analyze] Distributing to ${VALIDATOR_URLS.length} validators...`);
    
    const validatorResults = await distributeToValidators(
      taskId,
      audio,
      finalAudioHash
    );
    
    console.log(`[Analyze] Received ${validatorResults.length} responses`);
    
    // ========== 5. éªŒè¯ä¸€è‡´æ€§ ==========
    if (!verifyConsistency(validatorResults)) {
      return res.status(500).json({
        error: 'Validators returned inconsistent results',
        validator_count: validatorResults.length
      });
    }
    
    console.log(`[Analyze] Consistency check passed âœ“`);
    
    // ========== 6. æ„é€ å“åº” ==========
    const response = {
      task_id: taskId,
      audio_hash: finalAudioHash,
      
      // ä½¿ç”¨ç¬¬ä¸€ä¸ªéªŒè¯èŠ‚ç‚¹çš„åˆ†æç»“æœï¼ˆå› ä¸ºéƒ½ä¸€è‡´ï¼‰
      result: validatorResults[0].result_json,
      result_hash: validatorResults[0].result_hash,
      
      // åŒ…å«æ‰€æœ‰éªŒè¯èŠ‚ç‚¹çš„ç­¾å
      proof: {
        algo_version: validatorResults[0].algo_version,
        threshold: `${validatorResults.length}-of-${VALIDATOR_URLS.length}`,
        validators: validatorResults.map(v => ({
          validator_id: v.validator_id,
          public_key: v.public_key,
          signature: v.signature,
          timestamp: new Date(v.timestamp * 1000).toISOString()
        })),
        verified: true
      },
      
      timestamp: new Date().toISOString(),
      user_id: user_id,
      activity_id: activity_id || null
    };
    
    console.log(`[Analyze] Task ${taskId} completed successfully`);
    
    // ========== 7. è¿”å›ç»“æœ ==========
    res.json(response);
    
  } catch (error: any) {
    console.error('[Analyze] Error:', error);
    
    res.status(500).json({
      error: 'Analysis failed',
      message: error.message
    });
  }
});

/**
 * GET /api/analyze/health
 * 
 * æ£€æŸ¥éªŒè¯èŠ‚ç‚¹å¥åº·çŠ¶æ€
 */
router.get('/health', async (req: Request, res: Response) => {
  try {
    const healthChecks = await Promise.allSettled(
      VALIDATOR_URLS.map(async (url) => {
        const response = await axios.get(`${url}/health`, { timeout: 5000 });
        return {
          url,
          status: 'healthy',
          data: response.data
        };
      })
    );
    
    const results = healthChecks.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          url: VALIDATOR_URLS[index],
          status: 'unhealthy',
          error: result.reason.message
        };
      }
    });
    
    const healthyCount = results.filter(r => r.status === 'healthy').length;
    
    res.json({
      total_validators: VALIDATOR_URLS.length,
      healthy_validators: healthyCount,
      threshold: THRESHOLD,
      operational: healthyCount >= THRESHOLD,
      validators: results
    });
    
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});

export default router;
```

**ä¿å­˜å¹¶é€€å‡º**

---

## ğŸ”„ ç¬¬å…­æ­¥ï¼šé…ç½®ç¯å¢ƒå˜é‡

### 6.1 åˆ›å»º .env æ–‡ä»¶

```bash
# å›åˆ°é¡¹ç›®æ ¹ç›®å½•
cd ../../../..

# åˆ›å»º .env
nano .env
```

**å¤åˆ¶ä»¥ä¸‹å†…å®¹ï¼ˆå¡«å…¥ä½ ä¹‹å‰ç”Ÿæˆçš„å¯†é’¥ï¼‰ï¼š**

```bash
# Validator BLS Private Keys (å¡«å…¥ä½ ç”Ÿæˆçš„å¯†é’¥)
VALIDATOR_1_SK=0xä½ çš„ç§é’¥1
VALIDATOR_2_SK=0xä½ çš„ç§é’¥2
VALIDATOR_3_SK=0xä½ çš„ç§é’¥3

# Validator URLs
VALIDATOR_1_URL=http://localhost:8001
VALIDATOR_2_URL=http://localhost:8002
VALIDATOR_3_URL=http://localhost:8003

# Algorithm Version
ALGO_VERSION=sensevoice-small-v1.0.0

# Server Port
PORT=3000
```

**ä¿å­˜å¹¶é€€å‡º**

---

## ğŸš€ ç¬¬ä¸ƒæ­¥ï¼šå¯åŠ¨æœåŠ¡

ç°åœ¨å¯ä»¥å¯åŠ¨ä½ çš„æœåŠ¡äº†ï¼

### 7.1 å¯åŠ¨éªŒè¯èŠ‚ç‚¹ï¼ˆ3ä¸ªç»ˆç«¯ï¼‰

**ç»ˆç«¯ 1ï¼š**
```bash
cd services/ai
VALIDATOR_ID=1 BLS_PRIVATE_KEY=$(cat ../../scripts/validator_1_sk.key) python validator.py
```

**ç»ˆç«¯ 2ï¼š**
```bash
cd services/ai
VALIDATOR_ID=2 BLS_PRIVATE_KEY=$(cat ../../scripts/validator_2_sk.key) python validator.py
```

**ç»ˆç«¯ 3ï¼š**
```bash
cd services/ai
VALIDATOR_ID=3 BLS_PRIVATE_KEY=$(cat ../../scripts/validator_3_sk.key) python validator.py
```

ä½ åº”è¯¥çœ‹åˆ°æ¯ä¸ªéªŒè¯èŠ‚ç‚¹éƒ½å¯åŠ¨äº†ï¼š

```
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001
```

### 7.2 å¯åŠ¨ Node.js åç«¯ï¼ˆæ–°ç»ˆç«¯ï¼‰

**ç»ˆç«¯ 4ï¼š**
```bash
cd apps/server
npm run dev
```

---

## ğŸ§ª ç¬¬å…«æ­¥ï¼šæµ‹è¯• API

### 8.1 å¥åº·æ£€æŸ¥

```bash
# æµ‹è¯•åç«¯å¥åº·çŠ¶æ€
curl http://localhost:3000/api/analyze/health
```

åº”è¯¥è¿”å›ï¼š

```json
{
  "total_validators": 3,
  "healthy_validators": 3,
  "threshold": 2,
  "operational": true,
  "validators": [...]
}
```

### 8.2 æµ‹è¯•è¯­éŸ³åˆ†æ

åˆ›å»ºæµ‹è¯•è„šæœ¬ï¼š

```bash
nano test_analyze.sh
```

**å†…å®¹ï¼š**

```bash
#!/bin/bash

# æµ‹è¯•éŸ³é¢‘ï¼ˆä½ éœ€è¦æœ‰ä¸€ä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼‰
AUDIO_FILE="test_audio.wav"

# è½¬æ¢ä¸º base64
AUDIO_BASE64=$(base64 -w 0 $AUDIO_FILE)

# å‘é€è¯·æ±‚
curl -X POST http://localhost:3000/api/analyze \
  -H "Content-Type: application/json" \
  -d "{
    \"audio\": \"$AUDIO_BASE64\",
    \"user_id\": \"test_user_123\",
    \"activity_id\": \"hackathon_2026\"
  }" | jq '.'
```

**è¿è¡Œï¼š**

```bash
chmod +x test_analyze.sh
./test_analyze.sh
```

---

## âœ… å®Œæˆï¼

ç°åœ¨ä½ çš„ç³»ç»Ÿåº”è¯¥æ­£å¸¸è¿è¡Œäº†ï¼

### ä½ å®ç°çš„åŠŸèƒ½ï¼š

```
âœ… Node.js API æ¥æ”¶è¯­éŸ³ (POST /api/analyze)
âœ… 3 ä¸ª Python AI éªŒè¯èŠ‚ç‚¹
âœ… SenseVoice æƒ…æ„Ÿåˆ†æ
âœ… BLS ç­¾å
âœ… è¿”å›ï¼šå…¬é’¥ã€ç­¾åã€åˆ†æç»“æœ
```

---

## ğŸ“Š API è¿”å›ç¤ºä¾‹

```json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "audio_hash": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
  "result": {
    "emotion": "HAPPY",
    "intensity": 0.85,
    "keywords": ["æ´»åŠ¨", "å¾ˆæ£’"],
    "events": ["applause"],
    "raw_text": "è¿™æ¬¡æ´»åŠ¨ç»„ç»‡å¾—å¾ˆæ£’ï¼"
  },
  "result_hash": "b4c5d6e7f8...",
  "proof": {
    "algo_version": "sensevoice-small-v1.0.0",
    "threshold": "3-of-3",
    "validators": [
      {
        "validator_id": "1",
        "public_key": "0xa1b2c3...",
        "signature": "0x9876fe...",
        "timestamp": "2026-01-30T12:00:00Z"
      },
      {
        "validator_id": "2",
        "public_key": "0xf1e2d3...",
        "signature": "0x1234ab...",
        "timestamp": "2026-01-30T12:00:01Z"
      },
      {
        "validator_id": "3",
        "public_key": "0xc5d6e7...",
        "signature": "0x5678cd...",
        "timestamp": "2026-01-30T12:00:02Z"
      }
    ],
    "verified": true
  },
  "timestamp": "2026-01-30T12:00:03Z",
  "user_id": "test_user_123",
  "activity_id": "hackathon_2026"
}
```

---

## ğŸ†˜ é‡åˆ°é—®é¢˜ï¼Ÿ

### å¸¸è§é—®é¢˜æ’æŸ¥ï¼š

**1. éªŒè¯èŠ‚ç‚¹å¯åŠ¨å¤±è´¥**
```bash
# æ£€æŸ¥ä¾èµ–
pip list | grep funasr

# é‡æ–°å®‰è£…
pip install -r requirements.txt --break-system-packages
```

**2. æ¨¡å‹åŠ è½½å¤±è´¥**
```bash
# ç¡®è®¤æ¨¡å‹å·²ä¸‹è½½
ls ~/.cache/modelscope/hub/models/iic/

# é‡æ–°ä¸‹è½½
python -c "from modelscope import snapshot_download; snapshot_download('iic/SenseVoiceSmall')"
```

**3. BLS ç­¾åå¤±è´¥**
```bash
# æµ‹è¯• BLS æ¨¡å—
cd services/ai
python bls_signer.py
```

**4. Node.js è¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥éªŒè¯èŠ‚ç‚¹æ˜¯å¦è¿è¡Œ
curl http://localhost:8001/health
curl http://localhost:8002/health
curl http://localhost:8003/health
```

---

éœ€è¦æˆ‘ç»§ç»­å¸®ä½ è§£å†³ä»»ä½•é—®é¢˜å—ï¼Ÿ ğŸš€